{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cde9f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EE569 HOMEWORK ASSIGNMENT 6\n",
    "# DATE: Aprile 30th 2021\n",
    "# NAME: Siyu Li\n",
    "# ID:2455870216\n",
    "# E-mail:lisiyu@usc.edu\n",
    "# fashion_mnist\n",
    "# implement pixelhop by saab\n",
    "from pixelhop import Pixelhop\n",
    "import numpy as np\n",
    "from skimage.util import view_as_windows\n",
    "import pickle\n",
    "from skimage.measure import block_reduce\n",
    "import xgboost as xgb\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist,fashion_mnist\n",
    "import warnings, gc\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d380ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# Preprocess\n",
    "N_Train_Reduced = 10000    # 10000\n",
    "N_Train_Full = 60000     # 50000\n",
    "N_Test = 10000            # 10000\n",
    "\n",
    "BS = 10000 # batch size\n",
    "\n",
    "\n",
    "def shuffle_data(X, y):\n",
    "    shuffle_idx = np.random.permutation(y.size)\n",
    "    X = X[shuffle_idx]\n",
    "    y = y[shuffle_idx]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def select_balanced_subset(images, labels, use_num_images):\n",
    "    '''\n",
    "    select equal number of images from each classes\n",
    "    '''\n",
    "    num_total, H, W, C = images.shape\n",
    "    num_class = np.unique(labels).size\n",
    "    num_per_class = int(use_num_images / num_class)\n",
    "\n",
    "    # Shuffle\n",
    "    images, labels = shuffle_data(images, labels)\n",
    "\n",
    "    selected_images = np.zeros((use_num_images, H, W, C))\n",
    "    selected_labels = np.zeros(use_num_images)\n",
    "\n",
    "    for i in range(num_class):\n",
    "        selected_images[i * num_per_class:(i + 1) * num_per_class] = images[labels == i][:num_per_class]\n",
    "        selected_labels[i * num_per_class:(i + 1) * num_per_class] = np.ones((num_per_class)) * i\n",
    "\n",
    "    # Shuffle again\n",
    "    selected_images, selected_labels = shuffle_data(selected_images, selected_labels)\n",
    "\n",
    "    return selected_images, selected_labels\n",
    "\n",
    "def Shrink(X, shrinkArg):\n",
    "    #---- max pooling----\n",
    "    pool = shrinkArg['pool']\n",
    "    # TODO: fill in the rest of max pooling\n",
    "    X=block_reduce(X,(1,pool,pool,1),np.max)\n",
    "    \n",
    "    #---- neighborhood construction\n",
    "    win = shrinkArg['win']\n",
    "    stride = shrinkArg['stride']\n",
    "    pad = shrinkArg['pad']\n",
    "    ch=X.shape[-1]\n",
    "    # TODO: fill in the rest of neighborhood construction\n",
    "    if pad>0:\n",
    "        X=np.pad(X,((0,0),(pad,pad),(pad,pad),(0,0)),'reflect')\n",
    "    X=view_as_windows(X,(1,win,win,ch),(1,stride,stride,ch))\n",
    "    return X.reshape(X.shape[0],X.shape[1],X.shape[2],-1)\n",
    "\n",
    "# example callback function for how to concate features from different hops\n",
    "def Concat(X, concatArg):\n",
    "    return X\n",
    "\n",
    "def get_feat(X, num_layers=3):\n",
    "    output = p2.transform_singleHop(X,layer=0)\n",
    "    if num_layers>1:\n",
    "        for i in range(num_layers-1):\n",
    "            output = p2.transform_singleHop(output, layer=i+1)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0711fa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================>c/w Saab Train Hop 1\n",
      "=============================================>c/w Saab Train Hop 2\n",
      "=============================================>c/w Saab Train Hop 3\n",
      "k1:  23\n",
      "k2:  44\n",
      "k3:  42\n",
      "[21:25:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "training time is  183.0281023979187\n",
      "Training Set 60000 Predicted score = 0.9117333333333333\n",
      "Test Set Predicted score = 0.862\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # ---------- Load MNIST data and split ----------\n",
    "    (x_train, y_train), (x_test,y_test) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "    # -----------Data Preprocessing-----------\n",
    "    x_train = np.asarray(x_train,dtype='float32')[:,:,:,np.newaxis]\n",
    "    x_test = np.asarray(x_test,dtype='float32')[:,:,:,np.newaxis]\n",
    "    y_train = np.asarray(y_train,dtype='int')\n",
    "    y_test = np.asarray(y_test,dtype='int')\n",
    "\n",
    "    # if use only 10000 images train pixelhop\n",
    "    x_train_reduced, y_train_reduced = select_balanced_subset(x_train, y_train, use_num_images=N_Train_Reduced)\n",
    "\n",
    "    x_train /= 255.0\n",
    "    x_test /= 255.0\n",
    "\n",
    "\n",
    "    # -----------Module 1: set PixelHop parameters-----------\n",
    "    # TODO: fill in this part\n",
    "\n",
    "    SaabArgs = [{'num_AC_kernels':-1, 'needBias':False, 'cw':False}, \n",
    "            {'num_AC_kernels':-1, 'needBias':True, 'cw':False},\n",
    "            {'num_AC_kernels':-1, 'needBias':True, 'cw':False}]\n",
    "    shrinkArgs = [{'func':Shrink, 'win':5, 'stride':1, 'pad':2,'pool':1}, \n",
    "             {'func': Shrink, 'win':5, 'stride':1, 'pad':0, 'pool':2},\n",
    "             {'func': Shrink, 'win':5, 'stride':1,'pad':0, 'pool':2}]\n",
    "    concatArg = {'func':Concat}\n",
    "    \n",
    "\n",
    "    # -----------Module 1: Train PixelHop -----------\n",
    "    # TODO: fill in this part\n",
    "    \n",
    "    p2 = Pixelhop(depth=3, TH1=0.005, TH2=0.001, SaabArgs=SaabArgs, shrinkArgs=shrinkArgs, concatArg=concatArg)\n",
    "    p2.fit(x_train_reduced)\n",
    "\n",
    "    \n",
    "    # --------- Module 2: get only Hop 3 feature for both training set and testing set -----------\n",
    "    # you can get feature \"batch wise\" and concatenate them if your memory is restricted\n",
    "    # TODO: fill in this part\n",
    "    split_train_arr=[]\n",
    "    \n",
    "    for i in range(6):\n",
    "        temp=get_feat(x_train[i*BS:(i+1)*BS,:,:,:],3)\n",
    "        split_train_arr.append(temp)\n",
    "    train_hop3_feats=np.concatenate((split_train_arr[0],split_train_arr[1],split_train_arr[2],split_train_arr[3]\n",
    "                                     ,split_train_arr[4],split_train_arr[5]),axis=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #train_hop3_feats=get_feat(x_train,3)\n",
    "    test_hop3_feats=get_feat(x_test,3)\n",
    "    \n",
    "    ### Get Model Size\n",
    "    h1=get_feat(x_train_reduced,1).shape\n",
    "    h2=get_feat(x_train_reduced,2).shape\n",
    "    h3=get_feat(x_train_reduced,3).shape\n",
    "    \n",
    "    k1=h1[3]\n",
    "    k2=h2[3]\n",
    "    k3=h3[3]\n",
    "    \n",
    "    print('k1: ', k1)\n",
    "    print('k2: ', k2)\n",
    "    print('k3: ', k3)\n",
    "\n",
    "    # --------- Module 2: standardization\n",
    "    STD = np.std(train_hop3_feats, axis=0, keepdims=1)\n",
    "    train_hop3_feats = train_hop3_feats/STD ## size: (60000,1,1,70)\n",
    "    #print(np.shape(train_hop3_feats))\n",
    "    #STDtest = np.std(test_hop3_feats, axis=0, keepdims=1)\n",
    "    test_hop3_feats = test_hop3_feats/STD\n",
    "    \n",
    "    #---------- Module 3: Train XGBoost classifier on hop3 feature ---------\n",
    "    start_time = time.time()\n",
    "    tr_acc = []\n",
    "    te_acc = []\n",
    "    \n",
    "    clf = xgb.XGBClassifier(n_jobs=-1,\n",
    "                        objective='multi:softprob',\n",
    "                        # tree_method='gpu_hist', gpu_id=None,\n",
    "                        max_depth=6,n_estimators=100,\n",
    "                        min_child_weight=5,gamma=5,\n",
    "                        subsample=0.8,learning_rate=0.1,\n",
    "                        nthread=8,colsample_bytree=1.0)\n",
    "    clf.fit(np.squeeze(train_hop3_feats), np.squeeze(y_train))\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    print('training time is ', end_time - start_time)\n",
    "    # TODO: fill in the rest and report accuracy\n",
    "    score = clf.score(np.squeeze(train_hop3_feats), np.squeeze(y_train))\n",
    "    print('Training Set 60000 Predicted score =', score)\n",
    "    \n",
    "    score = clf.score(np.squeeze(test_hop3_feats), np.squeeze(y_test))\n",
    "    print('Test Set Predicted score =', score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b236aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
